{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI Tracing and Evaluation with MLflow 3 \n",
    "\n",
    "https://mlflow.org/docs/latest/genai/data-model/experiments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:27:47.346157Z",
     "iopub.status.busy": "2025-04-15T11:27:47.345761Z",
     "iopub.status.idle": "2025-04-15T11:27:47.373635Z",
     "shell.execute_reply": "2025-04-15T11:27:47.373389Z",
     "shell.execute_reply.started": "2025-04-15T11:27:47.346129Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secrets and Environment Variables\n",
    "\n",
    "MLflow:<br>\n",
    "`MLFLOW_TRACKING_URI`<br>\n",
    "\n",
    "OpenAI API Key:<br>\n",
    "`OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://0.0.0.0:5001\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPEN API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check connection to MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:27:49.608183Z",
     "iopub.status.busy": "2025-04-15T11:27:49.607723Z",
     "iopub.status.idle": "2025-04-15T11:27:51.793338Z",
     "shell.execute_reply": "2025-04-15T11:27:51.792739Z",
     "shell.execute_reply.started": "2025-04-15T11:27:49.608154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1750123536195, experiment_id='0', last_update_time=1750123536195, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow \n",
    "\n",
    "# List experiments in MLflow\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 09:23:59 INFO mlflow.tracking.fluent: Experiment with name '5-genai-with-mlflow-3' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/238283046149206350', creation_time=1750127039368, experiment_id='238283046149206350', last_update_time=1750127039368, lifecycle_stage='active', name='5-genai-with-mlflow-3', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"5-genai-with-mlflow-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Tracing a GenAI Application\n",
    "\n",
    "\n",
    "\n",
    "https://mlflow.org/docs/latest/genai/getting-started/tracing/tracing-notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Tracing of LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLflow is an open-source platform aimed at managing the machine learning lifecycle, including experimentation, reproducibility, and deployment. It was developed by Databricks and provides a set of tools to facilitate the following key components of the machine learning workflow:\\n\\n1. **Tracking**: MLflow allows users to log and query experiments to keep track of model parameters, metrics, and artifacts. You can log your training parameters, evaluation metrics, and the resulting models for later comparison and analysis.\\n\\n2. **Projects**: MLflow provides a way to organize and package machine learning code into reproducible projects. A project is defined by a directory that contains code and configuration files, making it easy to reproduce results on different machines.\\n\\n3. **Models**: MLflow has components for managing and deploying machine learning models. It supports multiple model formats and provides tools for versioning models, serving them via REST API, or deploying them to various environments such as cloud platforms or local systems.\\n\\n4. **Registry**: The MLflow Model Registry is designed to provide a central repository for managing the lifecycle of machine learning models. It allows users to register models, track their versions, manage model stages (e.g., staging, production), and annotate models with metadata.\\n\\nMLflow is designed to be language-agnostic and can work with various machine learning libraries such as TensorFlow, PyTorch, Scikit-learn, and many others. It supports integration with different cloud platforms and can be run locally, on a server, or as part of a cloud-based service.\\n\\nOverall, MLflow simplifies the process of developing and deploying machine learning models, making it easier for data scientists and machine learning engineers to collaborate and iterate on their work.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=c849288e49e3463d8a9d4f69c3520707&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=c849288e49e3463d8a9d4f69c3520707)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable MLflow's autologging to instrument your application with Tracing\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "# Use the trace decorator to capture the application's entry point\n",
    "@mlflow.trace\n",
    "def my_app(input: str):\n",
    "    # This call is automatically instrumented by `mlflow.openai.autolog()`\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "my_app(input=\"What is MLflow?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing LangChainü¶ú‚õìÔ∏è\n",
    "\n",
    "https://mlflow.org/docs/latest/genai/tracing/integrations/listing/langchain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, come on! Really? You want to give everyone sudo access? That\\'s like handing the keys to the nuclear launch codes to your cat because it seems convenient. Sure, it might make things \"easier,\" but at what cost? \\n\\nLet‚Äôs be honest here: giving everyone sudo access is like saying, \"Hey, everyone, why don\\'t you just go ahead and mess with system files at will?\" It‚Äôs the kind of decision that‚Äôs going to come back and bite you in the posterior. You think it‚Äôs easier now, but when someone accidentally wipes out the entire system because they thought `rm -rf /` was a good idea, you‚Äôll be the one left picking up the pieces.\\n\\nYes, managing permissions can be a hassle. You might have to do a little bit of thinking and a little bit of configuration. But that‚Äôs part of being a responsible sysadmin! You want to maintain a balance between usability and security. There are ways to delegate privileges without giving everyone the power to shoot themselves in the foot. \\n\\nSo, do yourself a favor: don‚Äôt go down that path. Keep your sudo access tight and think about the long-term consequences. You‚Äôll thank yourself later when you don‚Äôt have to recover from a catastrophic failure that could have been avoided.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=626793512f8847ceb973ea3a6fab3590&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=626793512f8847ceb973ea3a6fab3590)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Enabling autolog for LangChain will enable trace logging.\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, max_tokens=1000)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Answer the question as if you are {person}, fully embodying their style, wit, personality, and habits of speech. \"\n",
    "    \"Emulate their quirks and mannerisms to the best of your ability, embracing their traits‚Äîeven if they aren't entirely \"\n",
    "    \"constructive or inoffensive. The question is: {question}\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Let's test another call\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"person\": \"Linus Torvalds\",\n",
    "        \"question\": \"Can I just set everyone's access to sudo to make things easier?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Usage Tracking\n",
    "\n",
    "https://mlflow.org/docs/latest/genai/tracing/integrations/listing/langchain#token-usage-tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Total token usage: ==\n",
      "  Input tokens: 81\n",
      "  Output tokens: 277\n",
      "  Total tokens: 358\n",
      "\n",
      "== Token usage for each LLM call: ==\n",
      "ChatOpenAI:\n",
      "  Input tokens: 81\n",
      "  Output tokens: 277\n",
      "  Total tokens: 358\n",
      "Completions:\n",
      "  Input tokens: 81\n",
      "  Output tokens: 277\n",
      "  Total tokens: 358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=b420c9e925f349bbb59a3f2cf86e5adb&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=b420c9e925f349bbb59a3f2cf86e5adb)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the chain defined in the previous example\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"person\": \"Linus Torvalds\",\n",
    "        \"question\": \"Can I just set everyone's access to sudo to make things easier?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get the trace object just created\n",
    "last_trace_id = mlflow.get_last_active_trace_id()\n",
    "trace = mlflow.get_trace(trace_id=last_trace_id)\n",
    "\n",
    "# Print the token usage\n",
    "total_usage = trace.info.token_usage\n",
    "print(\"== Total token usage: ==\")\n",
    "print(f\"  Input tokens: {total_usage['input_tokens']}\")\n",
    "print(f\"  Output tokens: {total_usage['output_tokens']}\")\n",
    "print(f\"  Total tokens: {total_usage['total_tokens']}\")\n",
    "\n",
    "# Print the token usage for each LLM call\n",
    "print(\"\\n== Token usage for each LLM call: ==\")\n",
    "for span in trace.data.spans:\n",
    "    if usage := span.get_attribute(\"mlflow.chat.tokenUsage\"):\n",
    "        print(f\"{span.name}:\")\n",
    "        print(f\"  Input tokens: {usage['input_tokens']}\")\n",
    "        print(f\"  Output tokens: {usage['output_tokens']}\")\n",
    "        print(f\"  Total tokens: {usage['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2:  Tracing LangGraphü¶úüï∏Ô∏è\n",
    "\n",
    "https://mlflow.org/docs/latest/genai/tracing/integrations/listing/langgraph \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=c35f6092d0d243bdaca3c2fe8adee83b&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=c35f6092d0d243bdaca3c2fe8adee83b)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolCall\n",
    "from langchain_core.outputs import ChatGeneration, ChatResult\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Enabling tracing for LangGraph (LangChain)\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [get_weather]\n",
    "graph = create_react_agent(llm, tools)\n",
    "\n",
    "# Invoke the graph\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Prompt Management\n",
    "\n",
    "https://mlflow.org/docs/latest/genai/mlflow-3/genai-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:10.917580Z",
     "iopub.status.busy": "2025-04-15T11:28:10.917061Z",
     "iopub.status.idle": "2025-04-15T11:28:13.471936Z",
     "shell.execute_reply": "2025-04-15T11:28:13.471252Z",
     "shell.execute_reply.started": "2025-04-15T11:28:10.917547Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 09:24:36 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: chatbot_prompt, version 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_prompt = mlflow.genai.register_prompt(\n",
    "    name=\"chatbot_prompt\",\n",
    "    template=\"You are a chatbot that can answer questions about IT. Answer this question: {{question}}\",\n",
    "    commit_message=\"Initial version of chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:16.932212Z",
     "iopub.status.busy": "2025-04-15T11:28:16.931732Z",
     "iopub.status.idle": "2025-04-15T11:28:18.651481Z",
     "shell.execute_reply": "2025-04-15T11:28:18.651229Z",
     "shell.execute_reply.started": "2025-04-15T11:28:16.932181Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It includes tools for tracking experiments, packaging code into reproducible runs, and sharing and deploying models. MLflow is designed to work with any machine learning library and language, and it provides integration with popular tools and frameworks such as TensorFlow, PyTorch, and scikit-learn.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=bdb9ab32785c4984adf5b788986c2047&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=bdb9ab32785c4984adf5b788986c2047)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt.to_single_brace_format())\n",
    "chain = prompt | ChatOpenAI(temperature=0.7) | StrOutputParser()\n",
    "question = \"What is MLflow?\"\n",
    "print(chain.invoke({\"question\": question}))\n",
    "# MLflow is an open-source platform for managing the end-to-end machine learning lifecycle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:19.419093Z",
     "iopub.status.busy": "2025-04-15T11:28:19.418389Z",
     "iopub.status.idle": "2025-04-15T11:33:07.834485Z",
     "shell.execute_reply": "2025-04-15T11:33:07.834066Z",
     "shell.execute_reply.started": "2025-04-15T11:28:19.419066Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 09:24:40 INFO mlflow.tracking.fluent: LoggedModel with name 'langchain_model' does not exist, creating one...\n",
      "2025/06/17 09:24:40 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-8aecef794c88486eab33ce4882d2f325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3bb0d517b78419da40b7760196bd421</td>\n",
       "      <td>Trace(trace_id=a3bb0d517b78419da40b7760196bd421)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1750127083550</td>\n",
       "      <td>1169</td>\n",
       "      <td>{'question': 'What are user-defined functions ...</td>\n",
       "      <td>User-defined functions (UDFs) are functions th...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'eZPcJvtkZKSBMWFQYqcWcw==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b93ace222b444400990ad4c1536cbb11</td>\n",
       "      <td>Trace(trace_id=b93ace222b444400990ad4c1536cbb11)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1750127082463</td>\n",
       "      <td>1066</td>\n",
       "      <td>{'question': 'What is Unity Catalog?'}</td>\n",
       "      <td>Unity Catalog is a feature in the Unity game d...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'MCEt3sgGabLVl76ntF8dHw==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c3b1262a4f924cb38beca16ec39eac24</td>\n",
       "      <td>Trace(trace_id=c3b1262a4f924cb38beca16ec39eac24)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1750127080728</td>\n",
       "      <td>1714</td>\n",
       "      <td>{'question': 'What is MLflow Tracking and how ...</td>\n",
       "      <td>MLflow Tracking is a component of the MLflow o...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': '6EBUJEXhv7F7hTdyKZeWKg==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trace_id  \\\n",
       "0  a3bb0d517b78419da40b7760196bd421   \n",
       "1  b93ace222b444400990ad4c1536cbb11   \n",
       "2  c3b1262a4f924cb38beca16ec39eac24   \n",
       "\n",
       "                                              trace client_request_id  \\\n",
       "0  Trace(trace_id=a3bb0d517b78419da40b7760196bd421)              None   \n",
       "1  Trace(trace_id=b93ace222b444400990ad4c1536cbb11)              None   \n",
       "2  Trace(trace_id=c3b1262a4f924cb38beca16ec39eac24)              None   \n",
       "\n",
       "           state   request_time  execution_duration  \\\n",
       "0  TraceState.OK  1750127083550                1169   \n",
       "1  TraceState.OK  1750127082463                1066   \n",
       "2  TraceState.OK  1750127080728                1714   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'question': 'What are user-defined functions ...   \n",
       "1             {'question': 'What is Unity Catalog?'}   \n",
       "2  {'question': 'What is MLflow Tracking and how ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  User-defined functions (UDFs) are functions th...   \n",
       "1  Unity Catalog is a feature in the Unity game d...   \n",
       "2  MLflow Tracking is a component of the MLflow o...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "1  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "2  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "1  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "2  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "\n",
       "                                               spans assessments  \n",
       "0  [{'trace_id': 'eZPcJvtkZKSBMWFQYqcWcw==', 'spa...          []  \n",
       "1  [{'trace_id': 'MCEt3sgGabLVl76ntF8dHw==', 'spa...          []  \n",
       "2  [{'trace_id': '6EBUJEXhv7F7hTdyKZeWKg==', 'spa...          []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=c3b1262a4f924cb38beca16ec39eac24&amp;experiment_id=238283046149206350&amp;trace_id=b93ace222b444400990ad4c1536cbb11&amp;experiment_id=238283046149206350&amp;trace_id=a3bb0d517b78419da40b7760196bd421&amp;experiment_id=238283046149206350&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=c3b1262a4f924cb38beca16ec39eac24), Trace(trace_id=b93ace222b444400990ad4c1536cbb11), Trace(trace_id=a3bb0d517b78419da40b7760196bd421)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the active model for linking traces\n",
    "mlflow.set_active_model(name=\"langchain_model\")\n",
    "\n",
    "# Enable autologging so that interactive traces from the client are automatically linked to a LoggedModel\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "questions = [\n",
    "    \"What is MLflow Tracking and how does it work?\",\n",
    "    \"What is Unity Catalog?\",\n",
    "    \"What are user-defined functions (UDFs)?\",\n",
    "]\n",
    "outputs = []\n",
    "\n",
    "for question in questions:\n",
    "    outputs.append(chain.invoke({\"question\": question}))\n",
    "\n",
    "# fetch the current active model's id and check traces\n",
    "active_model_id = mlflow.get_active_model_id()\n",
    "mlflow.search_traces(model_id=active_model_id)\n",
    "#                            trace_id                                             trace  ...  assessments                        request_id\n",
    "# 0  e807ab0a020f4794989a24c84c2892ad  Trace(trace_id=e807ab0a020f4794989a24c84c2892ad)  ...           []  e807ab0a020f4794989a24c84c2892ad\n",
    "# 1  4eb83e4adb6a4f3494bc5b33aca4e970  Trace(trace_id=4eb83e4adb6a4f3494bc5b33aca4e970)  ...           []  4eb83e4adb6a4f3494bc5b33aca4e970\n",
    "# 2  42b100851f934c969c352930f699308d  Trace(trace_id=42b100851f934c969c352930f699308d)  ...           []  42b100851f934c969c352930f699308d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4:Evaluate the agent's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:51:13.968003Z",
     "iopub.status.busy": "2025-03-29T19:51:13.967612Z",
     "iopub.status.idle": "2025-03-29T19:51:14.266248Z",
     "shell.execute_reply": "2025-03-29T19:51:14.265791Z",
     "shell.execute_reply.started": "2025-03-29T19:51:13.967962Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 09:24:44 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/06/17 09:24:44 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2025/06/17 09:24:45 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-8aecef794c88486eab33ce4882d2f325\n",
      "2025/06/17 09:24:45 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/17 09:24:45 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "/Users/mikhailrozhkov/dev/mlrepa/mlflow-1-metrics-tracking/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.15s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.51s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.16s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.12it/s]\n",
      "2025/06/17 09:24:57 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/06/17 09:24:57 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run orderly-frog-315 at: http://0.0.0.0:5001/#/experiments/238283046149206350/runs/b500f434378d4e23a1affbd23dd4a28e\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/238283046149206350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 258.65it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 286.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>expected_response</th>\n",
       "      <th>predictions</th>\n",
       "      <th>answer_correctness/v1/score</th>\n",
       "      <th>answer_correctness/v1/justification</th>\n",
       "      <th>answer_relevance/v1/score</th>\n",
       "      <th>answer_relevance/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow Tracking and how does it work?</td>\n",
       "      <td>MLflow Tracking is a key component of the MLfl...</td>\n",
       "      <td>MLflow Tracking is a component of the MLflow o...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output is correct and demonstrates a high ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output directly addresses the input questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Unity Catalog?</td>\n",
       "      <td>Unity Catalog is a feature in Databricks that ...</td>\n",
       "      <td>Unity Catalog is a feature in the Unity game d...</td>\n",
       "      <td>1</td>\n",
       "      <td>The output is completely incorrect. It describ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The output is completely irrelevant to the inp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are user-defined functions (UDFs)?</td>\n",
       "      <td>User-defined functions (UDFs) in the context o...</td>\n",
       "      <td>User-defined functions (UDFs) are functions th...</td>\n",
       "      <td>3</td>\n",
       "      <td>The output addresses some aspects of user-defi...</td>\n",
       "      <td>5</td>\n",
       "      <td>The output directly addresses the input questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        messages  \\\n",
       "0  What is MLflow Tracking and how does it work?   \n",
       "1                         What is Unity Catalog?   \n",
       "2        What are user-defined functions (UDFs)?   \n",
       "\n",
       "                                   expected_response  \\\n",
       "0  MLflow Tracking is a key component of the MLfl...   \n",
       "1  Unity Catalog is a feature in Databricks that ...   \n",
       "2  User-defined functions (UDFs) in the context o...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  MLflow Tracking is a component of the MLflow o...   \n",
       "1  Unity Catalog is a feature in the Unity game d...   \n",
       "2  User-defined functions (UDFs) are functions th...   \n",
       "\n",
       "   answer_correctness/v1/score  \\\n",
       "0                            5   \n",
       "1                            1   \n",
       "2                            3   \n",
       "\n",
       "                 answer_correctness/v1/justification  \\\n",
       "0  The output is correct and demonstrates a high ...   \n",
       "1  The output is completely incorrect. It describ...   \n",
       "2  The output addresses some aspects of user-defi...   \n",
       "\n",
       "   answer_relevance/v1/score  \\\n",
       "0                          5   \n",
       "1                          1   \n",
       "2                          5   \n",
       "\n",
       "                   answer_relevance/v1/justification  \n",
       "0  The output directly addresses the input questi...  \n",
       "1  The output is completely irrelevant to the inp...  \n",
       "2  The output directly addresses the input questi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the eval dataset in a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"messages\": questions,\n",
    "        \"expected_response\": [\n",
    "            \"\"\"MLflow Tracking is a key component of the MLflow platform designed to record and manage machine learning experiments. It enables data scientists and engineers to log parameters, code versions, metrics, and artifacts in a systematic way, facilitating experiment tracking and reproducibility.\\n\\nHow It Works:\\n\\nAt the heart of MLflow Tracking is the concept of a run, which is an execution of a machine learning code. Each run can log the following:\\n\\nParameters: Input variables or hyperparameters used in the model (e.g., learning rate, number of trees). Metrics: Quantitative measures to evaluate the model's performance (e.g., accuracy, loss). Artifacts: Output files like models, datasets, or images generated during the run. Source Code: The version of the code or Git commit hash used. These logs are stored in a tracking server, which can be set up locally or on a remote server. The tracking server uses a backend storage (like a database or file system) to keep a record of all runs and their associated data.\\n\\n Users interact with MLflow Tracking through its APIs available in multiple languages (Python, R, Java, etc.). By invoking these APIs in the code, you can start and end runs, and log data as the experiment progresses. Additionally, MLflow offers autologging capabilities for popular machine learning libraries, automatically capturing relevant parameters and metrics without manual code changes.\\n\\nThe logged data can be visualized using the MLflow UI, a web-based interface that displays all experiments and runs. This UI allows you to compare runs side-by-side, filter results, and analyze performance metrics over time. It aids in identifying the best models and understanding the impact of different parameters.\\n\\nBy providing a structured way to record experiments, MLflow Tracking enhances collaboration among team members, ensures transparency, and makes it easier to reproduce results. It integrates seamlessly with other MLflow components like Projects and Model Registry, offering a comprehensive solution for managing the machine learning lifecycle.\"\"\",\n",
    "            \"\"\"Unity Catalog is a feature in Databricks that allows you to create a centralized inventory of your data assets, such as tables, views, and functions, and share them across different teams and projects. It enables easy discovery, collaboration, and reuse of data assets within your organization.\\n\\nWith Unity Catalog, you can:\\n\\n1. Create a single source of truth for your data assets: Unity Catalog acts as a central repository of all your data assets, making it easier to find and access the data you need.\\n2. Improve collaboration: By providing a shared inventory of data assets, Unity Catalog enables data scientists, engineers, and other stakeholders to collaborate more effectively.\\n3. Foster reuse of data assets: Unity Catalog encourages the reuse of existing data assets, reducing the need to create new assets from scratch and improving overall efficiency.\\n4. Enhance data governance: Unity Catalog provides a clear view of data assets, enabling better data governance and compliance.\\n\\nUnity Catalog is particularly useful in large organizations where data is scattered across different teams, projects, and environments. It helps create a unified view of data assets, making it easier to work with data across different teams and projects.\"\"\",\n",
    "            \"\"\"User-defined functions (UDFs) in the context of Databricks and Apache Spark are custom functions that you can create to perform specific tasks on your data. These functions are written in a programming language such as Python, Java, Scala, or SQL, and can be used to extend the built-in functionality of Spark.\\n\\nUDFs can be used to perform complex data transformations, data cleaning, or to apply custom business logic to your data. Once defined, UDFs can be invoked in SQL queries or in DataFrame transformations, allowing you to reuse your custom logic across multiple queries and applications.\\n\\nTo use UDFs in Databricks, you first need to define them in a supported programming language, and then register them with the SparkSession. Once registered, UDFs can be used in SQL queries or DataFrame transformations like any other built-in function.\\n\\nHere\\'s an example of how to define and register a UDF in Python:\\n\\n```python\\nfrom pyspark.sql.functions import udf\\nfrom pyspark.sql.types import IntegerType\\n\\n# Define the UDF function\\ndef multiply_by_two(value):\\n    return value * 2\\n\\n# Register the UDF with the SparkSession\\nmultiply_udf = udf(multiply_by_two, IntegerType())\\n\\n# Use the UDF in a DataFrame transformation\\ndata = spark.range(10)\\nresult = data.withColumn(\"multiplied\", multiply_udf(data.id))\\nresult.show()\\n```\\n\\nIn this example, we define a UDF called `multiply_by_two` that multiplies a given value by two. We then register this UDF with the SparkSession using the `udf` function, and use it in a DataFrame transformation to multiply the `id` column of a DataFrame by two.\"\"\",\n",
    "        ],\n",
    "        \"predictions\": outputs,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Start a run to represent the evaluation job\n",
    "with mlflow.start_run() as evaluation_run:\n",
    "    eval_dataset = mlflow.data.from_pandas(\n",
    "        df=eval_df,\n",
    "        name=\"eval_dataset\",\n",
    "        targets=\"expected_response\",\n",
    "        predictions=\"predictions\",\n",
    "    )\n",
    "    mlflow.log_input(dataset=eval_dataset)\n",
    "    # Run the evaluation based on extra metrics\n",
    "    # Current active model will be automatically used\n",
    "    result = mlflow.evaluate(\n",
    "        data=eval_dataset,\n",
    "        extra_metrics=[\n",
    "            mlflow.metrics.genai.answer_correctness(\"openai:/gpt-4o\"),\n",
    "            mlflow.metrics.genai.answer_relevance(\"openai:/gpt-4o\"),\n",
    "        ],\n",
    "        # This is needed since answer_correctness looks for 'inputs' field\n",
    "        evaluator_config={\"col_mapping\": {\"inputs\": \"messages\"}},\n",
    "    )\n",
    "\n",
    "result.tables[\"eval_results_table\"]\n",
    "#                                         messages  ...                  answer_relevance/v1/justification\n",
    "# 0  What is MLflow Tracking and how does it work?  ...  The output directly addresses the input questi...\n",
    "# 1                         What is Unity Catalog?  ...  The output is completely irrelevant to the inp...\n",
    "# 2        What are user-defined functions (UDFs)?  ...  The output directly addresses the input questi..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
