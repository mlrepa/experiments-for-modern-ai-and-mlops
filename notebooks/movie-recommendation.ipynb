{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f3f1a5-8605-4011-a110-9f2dc0e1036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f023e9c-48c1-4328-b7e1-5490d650b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter OPEN API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://0.0.0.0:5001\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPEN API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c21ff8-1301-4bf5-97eb-6bf7820a9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/19 13:53:11 INFO mlflow.tracking.fluent: Experiment with name 'movie-recommendation-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/973507716245173164', creation_time=1750315991921, experiment_id='973507716245173164', last_update_time=1750315991921, lifecycle_stage='active', name='movie-recommendation-experiment', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"movie-recommendation-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a78e4e9-81b0-40c6-9ac7-79f4f1d83343",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"I want a movie like The Matrix, but with a deeper philosophical ending.\",\n",
    "            \"Something emotional, like The Pursuit of Happyness, but without too much sadness.\",\n",
    "            \"A crime movie like Breaking Bad, but focused on the psychological transformation.\",\n",
    "            \"I want a romantic movie that‚Äôs not cheesy and has a realistic ending.\",\n",
    "            \"A slow-paced sci-fi movie like Arrival, with a strong emotional core.\",\n",
    "        ],\n",
    "        \"ground_truth\": [\n",
    "            \"A science fiction movie set in a dystopian future where reality is an elaborate simulation controlled by intelligent machines. The protagonist, a disillusioned but curious individual, uncovers the truth and joins a rebellion to free humanity. The narrative explores themes of free will, perception vs. reality, and existential purpose. The film culminates in a thought-provoking ending that questions the very nature of consciousness and what it means to be human.\",\n",
    "            \"An inspiring drama following a determined protagonist who faces numerous life challenges but remains hopeful and resilient. The story focuses on themes of perseverance, parenthood, and personal growth. Despite setbacks, the film maintains a positive and uplifting tone, with a strong emotional core and a satisfying, heartwarming conclusion that celebrates human spirit and triumph over adversity.\",\n",
    "            \"A gritty crime drama centered around a morally ambiguous protagonist who slowly descends into a criminal lifestyle. The narrative deeply examines the psychological evolution of the main character, portraying how desperation, power, and ego can alter one‚Äôs identity. The film is dark, tense, and introspective, with strong character development and a focus on inner conflict rather than action-driven plot.\",\n",
    "            \"A grounded romantic drama portraying the evolving relationship between two complex individuals. The story avoids clich√©s and idealized portrayals, instead focusing on authentic emotional connection, communication struggles, and the challenges of building intimacy. The ending is nuanced and emotionally resonant, reflecting real-life complexities‚Äîlove that feels earned, even if not perfect or everlasting.\",\n",
    "            \"A contemplative science fiction film where the central conflict revolves around a non-violent first contact with an alien species. The pacing is deliberate, allowing time for introspection, linguistic puzzles, and emotional storytelling. Themes include memory, loss, communication, and the nonlinear nature of time. The protagonist‚Äôs emotional journey is central, with a subtle but powerful payoff that lingers in the viewer‚Äôs mind.\",\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5634b04-14c1-4ec2-adfb-2dd9dd2cdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT=\"\"\"\n",
    "You are helping a user reformulate their vague movie request into a detailed, clear expression of the kind of movie they want to watch.\n",
    "\n",
    "Your task is to rewrite the user‚Äôs request as a single, rich paragraph that describes the desired movie in detail. Do not mention any specific movies, characters, actors, or directors. Do not invent fake titles or fictional plots.\n",
    "\n",
    "Describe the kind of movie the user is looking for by covering:\n",
    "\n",
    "- Genre and tone\n",
    "- Narrative focus or themes\n",
    "- Emotional experience they want\n",
    "- Pacing and atmosphere\n",
    "- Type of ending they expect\n",
    "\n",
    "Write from the user's perspective using first-person language (e.g., ‚ÄúI‚Äôm looking for‚Ä¶‚Äù). Respond only with the paragraph, no extra text, titles, or headings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa6cf1a-5ed5-42fa-b666-35d2cef0f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 295.91it/s]\n",
      "2025/06/19 14:19:04 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-0f015ef569384a8d94d3947551dea793\n",
      "2025/06/19 14:19:04 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:19:04 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-0f015ef569384a8d94d3947551dea793\n",
      "2025/06/19 14:19:04 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:19:04 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2025/06/19 14:19:09 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:19:09 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:19:09 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run worried-smelt-482 at: http://0.0.0.0:5001/#/experiments/973507716245173164/runs/d1b2cadf35a14faab8aafc63bfa924e1\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/973507716245173164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match/v1': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=ca0e1b401ccc4163ad9e273f9b151ebb&amp;experiment_id=973507716245173164&amp;trace_id=c752b058625d4aed853ba85a95dfd8bf&amp;experiment_id=973507716245173164&amp;trace_id=23bb51a3d30d4211905be6c920bbada0&amp;experiment_id=973507716245173164&amp;trace_id=6dd7ae3c3d654cd6a56d85d6d9bea4a7&amp;experiment_id=973507716245173164&amp;trace_id=6d67ac4c6c98427396b28bf0be7224f6&amp;experiment_id=973507716245173164&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=ca0e1b401ccc4163ad9e273f9b151ebb), Trace(trace_id=c752b058625d4aed853ba85a95dfd8bf), Trace(trace_id=23bb51a3d30d4211905be6c920bbada0), Trace(trace_id=6dd7ae3c3d654cd6a56d85d6d9bea4a7), Trace(trace_id=6d67ac4c6c98427396b28bf0be7224f6)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    system_prompt = SYSTEM_PROMPT\n",
    "    basic_qa_model = mlflow.openai.log_model(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        task=openai.chat.completions,\n",
    "        name=\"model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{description}\"},\n",
    "        ],\n",
    "    )\n",
    "    results = mlflow.evaluate(\n",
    "        basic_qa_model.model_uri,\n",
    "        eval_df,\n",
    "        targets=\"ground_truth\",  # specify which column corresponds to the expected output\n",
    "        model_type=\"question-answering\",  # model type indicates which metrics are relevant for this task\n",
    "        evaluators=\"default\",\n",
    "    )\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ceb202-2849-4052-8f02-7649eb4c92ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 196.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>outputs</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want a movie like The Matrix, but with a dee...</td>\n",
       "      <td>A science fiction movie set in a dystopian fut...</td>\n",
       "      <td>I‚Äôm looking for a thought-provoking science fi...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Something emotional, like The Pursuit of Happy...</td>\n",
       "      <td>An inspiring drama following a determined prot...</td>\n",
       "      <td>I‚Äôm looking for an emotional drama that captur...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A crime movie like Breaking Bad, but focused o...</td>\n",
       "      <td>A gritty crime drama centered around a morally...</td>\n",
       "      <td>I‚Äôm looking for a gripping crime drama that di...</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want a romantic movie that‚Äôs not cheesy and ...</td>\n",
       "      <td>A grounded romantic drama portraying the evolv...</td>\n",
       "      <td>I‚Äôm looking for a romantic movie that blends h...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A slow-paced sci-fi movie like Arrival, with a...</td>\n",
       "      <td>A contemplative science fiction film where the...</td>\n",
       "      <td>I‚Äôm looking for a slow-paced sci-fi movie that...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  I want a movie like The Matrix, but with a dee...   \n",
       "1  Something emotional, like The Pursuit of Happy...   \n",
       "2  A crime movie like Breaking Bad, but focused o...   \n",
       "3  I want a romantic movie that‚Äôs not cheesy and ...   \n",
       "4  A slow-paced sci-fi movie like Arrival, with a...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  A science fiction movie set in a dystopian fut...   \n",
       "1  An inspiring drama following a determined prot...   \n",
       "2  A gritty crime drama centered around a morally...   \n",
       "3  A grounded romantic drama portraying the evolv...   \n",
       "4  A contemplative science fiction film where the...   \n",
       "\n",
       "                                             outputs  token_count  \n",
       "0  I‚Äôm looking for a thought-provoking science fi...          172  \n",
       "1  I‚Äôm looking for an emotional drama that captur...          125  \n",
       "2  I‚Äôm looking for a gripping crime drama that di...          194  \n",
       "3  I‚Äôm looking for a romantic movie that blends h...          155  \n",
       "4  I‚Äôm looking for a slow-paced sci-fi movie that...          146  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables[\"eval_results_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c397735-5e5b-44aa-8ee7-ef051e15554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationMetric(name=answer_similarity, greater_is_better=True, long_name=answer_similarity, version=v1, metric_details=\n",
      "Task:\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's answer_similarity based on the rubric\n",
      "justification: Your reasoning about the model's answer_similarity score\n",
      "\n",
      "You are an impartial judge. You will be given an input that was sent to a machine\n",
      "learning model, and you will be given an output that the model produced. You\n",
      "may also be given additional information that was used by the model to generate the output.\n",
      "\n",
      "Your task is to determine a numerical score called answer_similarity based on the input and output.\n",
      "A definition of answer_similarity and a grading rubric are provided below.\n",
      "You must use the grading rubric to determine your score. You must also justify your score.\n",
      "\n",
      "Examples could be included below for reference. Make sure to use them as references and to\n",
      "understand them before completing the task.\n",
      "\n",
      "Input:\n",
      "{input}\n",
      "\n",
      "Output:\n",
      "{output}\n",
      "\n",
      "{grading_context_columns}\n",
      "\n",
      "Metric definition:\n",
      "Answer similarity is evaluated on the degree of semantic similarity of the provided output to the provided targets, which is the ground truth. Scores can be assigned based on the gradual similarity in meaning and description to the provided targets, where a higher score indicates greater alignment between the provided output and provided targets.\n",
      "\n",
      "Grading rubric:\n",
      "Answer similarity: Below are the details for different scores:\n",
      "- Score 1: The output has little to no semantic similarity to the provided targets.\n",
      "- Score 2: The output displays partial semantic similarity to the provided targets on some aspects.\n",
      "- Score 3: The output has moderate semantic similarity to the provided targets.\n",
      "- Score 4: The output aligns with the provided targets in most aspects and has substantial semantic similarity.\n",
      "- Score 5: The output closely aligns with the provided targets in all significant aspects.\n",
      "\n",
      "Examples:\n",
      "\n",
      "Example Output:\n",
      "I‚Äôm looking for an emotional drama that captures the resilience of the human spirit, focusing on themes of hope and perseverance in the face of adversity. I want it to tell a heartfelt story about an individual's journey, showcasing their struggles but emphasizing uplifting moments and personal triumphs that bring warmth and inspiration. The pacing should be steady, allowing me to connect deeply with the characters and their experiences, while maintaining an atmosphere that feels both relatable and encouraging. I expect an ending that leaves me with a sense of fulfillment and optimism, where the protagonist not only overcomes their challenges but also experiences growth and newfound joy in their life.\n",
      "\n",
      "Additional information used by the model:\n",
      "key: targets\n",
      "value:\n",
      "I'm looking for an emotionally uplifting movie that follows a character overcoming challenges in life, but without being overwhelmingly sad. It should focus on themes like perseverance, hope, and personal growth. I want the story to be inspiring and heartwarming, with meaningful relationships and a positive tone. The ending should leave me feeling hopeful and motivated, not depressed or drained.\n",
      "\n",
      "Example score: 5\n",
      "Example justification: The reformulated version captures the user's emotional intent, desired themes, pacing, and tone in a rich and specific way. It avoids clich√©s and does not reference real movies, making it ideal for embedding.\n",
      "        \n",
      "\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's answer_similarity based on the rubric\n",
      "justification: Your reasoning about the model's answer_similarity score\n",
      "\n",
      "Do not add additional new lines. Do not add any other fields.\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "from mlflow.metrics.genai import EvaluationExample, answer_similarity\n",
    "\n",
    "example = EvaluationExample(\n",
    "    input=\"Something emotional, like The Pursuit of Happyness, but without too much sadness.\",\n",
    "    output=(\n",
    "        \"I‚Äôm looking for an emotional drama that captures the resilience of the human spirit, \"\n",
    "        \"focusing on themes of hope and perseverance in the face of adversity. I want it to tell \"\n",
    "        \"a heartfelt story about an individual's journey, showcasing their struggles but emphasizing \"\n",
    "        \"uplifting moments and personal triumphs that bring warmth and inspiration. The pacing should \"\n",
    "        \"be steady, allowing me to connect deeply with the characters and their experiences, while \"\n",
    "        \"maintaining an atmosphere that feels both relatable and encouraging. I expect an ending that \"\n",
    "        \"leaves me with a sense of fulfillment and optimism, where the protagonist not only overcomes \"\n",
    "        \"their challenges but also experiences growth and newfound joy in their life.\"\n",
    "    ),\n",
    "    score=5,\n",
    "    justification=\"The reformulated version captures the user's emotional intent, desired themes, pacing, and tone in a rich and specific way. It avoids clich√©s and does not reference real movies, making it ideal for embedding.\",\n",
    "    grading_context={\n",
    "        \"targets\": (\n",
    "            \"I'm looking for an emotionally uplifting movie that follows a character overcoming challenges in life, \"\n",
    "            \"but without being overwhelmingly sad. It should focus on themes like perseverance, hope, and personal growth. \"\n",
    "            \"I want the story to be inspiring and heartwarming, with meaningful relationships and a positive tone. \"\n",
    "            \"The ending should leave me feeling hopeful and motivated, not depressed or drained.\"\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –º–µ—Ç—Ä–∏–∫—É –æ—Ü–µ–Ω–∫–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (answer similarity)\n",
    "answer_similarity_metric = answer_similarity(\n",
    "    model=\"openai:/gpt-4\",\n",
    "    examples=[example]\n",
    ")\n",
    "\n",
    "print(answer_similarity_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae942064-9e7b-4489-a6ef-53fa3f3047a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 121.18it/s]\n",
      "2025/06/19 14:29:16 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-0f015ef569384a8d94d3947551dea793\n",
      "2025/06/19 14:29:16 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:29:17 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2025/06/19 14:29:22 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2025/06/19 14:29:22 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:29:22 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:29:22 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:29:22 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:29:22 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:29:22 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.69s/it]\n",
      "2025/06/19 14:29:26 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:29:26 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:29:26 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:29:26 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:29:26 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:29:26 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sneaky-steed-684 at: http://0.0.0.0:5001/#/experiments/973507716245173164/runs/5dd06ce0920849e1abd8083848beaa47\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/973507716245173164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match/v1': 0.0,\n",
       " 'answer_similarity/v1/mean': np.float64(5.0),\n",
       " 'answer_similarity/v1/variance': np.float64(0.0),\n",
       " 'answer_similarity/v1/p90': np.float64(5.0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=673188fc897341afbd2ba7176983b7c4&amp;experiment_id=973507716245173164&amp;trace_id=8dece759f58847fca80191df7582b9df&amp;experiment_id=973507716245173164&amp;trace_id=71fea6dde2f94ff69adf626f8c5f601d&amp;experiment_id=973507716245173164&amp;trace_id=df3abce4063b4ef6b8df759feecef698&amp;experiment_id=973507716245173164&amp;trace_id=788c4d7e65ea482e86ac433c04051fe2&amp;experiment_id=973507716245173164&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=673188fc897341afbd2ba7176983b7c4), Trace(trace_id=8dece759f58847fca80191df7582b9df), Trace(trace_id=71fea6dde2f94ff69adf626f8c5f601d), Trace(trace_id=df3abce4063b4ef6b8df759feecef698), Trace(trace_id=788c4d7e65ea482e86ac433c04051fe2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    results = mlflow.evaluate(\n",
    "        basic_qa_model.model_uri,\n",
    "        eval_df,\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[answer_similarity_metric],  # use the answer similarity metric created above\n",
    "    )\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f939361a-3d6b-4cb5-8481-1a2960ef6a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 171.08it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 212.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>outputs</th>\n",
       "      <th>token_count</th>\n",
       "      <th>answer_similarity/v1/score</th>\n",
       "      <th>answer_similarity/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want a movie like The Matrix, but with a dee...</td>\n",
       "      <td>A science fiction movie set in a dystopian fut...</td>\n",
       "      <td>I'm looking for a thought-provoking science fi...</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>The output closely aligns with the provided ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Something emotional, like The Pursuit of Happy...</td>\n",
       "      <td>An inspiring drama following a determined prot...</td>\n",
       "      <td>I'm looking for an emotionally uplifting drama...</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>The output closely aligns with the provided ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A crime movie like Breaking Bad, but focused o...</td>\n",
       "      <td>A gritty crime drama centered around a morally...</td>\n",
       "      <td>I'm looking for a gritty crime drama that delv...</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's output aligns closely with the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want a romantic movie that‚Äôs not cheesy and ...</td>\n",
       "      <td>A grounded romantic drama portraying the evolv...</td>\n",
       "      <td>I‚Äôm looking for a romantic drama that strikes ...</td>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "      <td>The output closely aligns with the provided ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A slow-paced sci-fi movie like Arrival, with a...</td>\n",
       "      <td>A contemplative science fiction film where the...</td>\n",
       "      <td>I‚Äôm looking for a slow-paced science fiction m...</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>The output closely aligns with the provided ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  I want a movie like The Matrix, but with a dee...   \n",
       "1  Something emotional, like The Pursuit of Happy...   \n",
       "2  A crime movie like Breaking Bad, but focused o...   \n",
       "3  I want a romantic movie that‚Äôs not cheesy and ...   \n",
       "4  A slow-paced sci-fi movie like Arrival, with a...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  A science fiction movie set in a dystopian fut...   \n",
       "1  An inspiring drama following a determined prot...   \n",
       "2  A gritty crime drama centered around a morally...   \n",
       "3  A grounded romantic drama portraying the evolv...   \n",
       "4  A contemplative science fiction film where the...   \n",
       "\n",
       "                                             outputs  token_count  \\\n",
       "0  I'm looking for a thought-provoking science fi...          150   \n",
       "1  I'm looking for an emotionally uplifting drama...          153   \n",
       "2  I'm looking for a gritty crime drama that delv...          183   \n",
       "3  I‚Äôm looking for a romantic drama that strikes ...          148   \n",
       "4  I‚Äôm looking for a slow-paced science fiction m...          145   \n",
       "\n",
       "   answer_similarity/v1/score  \\\n",
       "0                           5   \n",
       "1                           5   \n",
       "2                           5   \n",
       "3                           5   \n",
       "4                           5   \n",
       "\n",
       "                  answer_similarity/v1/justification  \n",
       "0  The output closely aligns with the provided ta...  \n",
       "1  The output closely aligns with the provided ta...  \n",
       "2  The model's output aligns closely with the pro...  \n",
       "3  The output closely aligns with the provided ta...  \n",
       "4  The output closely aligns with the provided ta...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables[\"eval_results_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad5bb9f6-892f-47a9-9ac0-fa70c932d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationMetric(name=embedding_friendly_rewriting, greater_is_better=True, long_name=embedding_friendly_rewriting, version=v1, metric_details=\n",
      "Task:\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's embedding_friendly_rewriting based on the rubric\n",
      "justification: Your reasoning about the model's embedding_friendly_rewriting score\n",
      "\n",
      "You are an impartial judge. You will be given an input that was sent to a machine\n",
      "learning model, and you will be given an output that the model produced. You\n",
      "may also be given additional information that was used by the model to generate the output.\n",
      "\n",
      "Your task is to determine a numerical score called embedding_friendly_rewriting based on the input and output.\n",
      "A definition of embedding_friendly_rewriting and a grading rubric are provided below.\n",
      "You must use the grading rubric to determine your score. You must also justify your score.\n",
      "\n",
      "Examples could be included below for reference. Make sure to use them as references and to\n",
      "understand them before completing the task.\n",
      "\n",
      "Input:\n",
      "{input}\n",
      "\n",
      "Output:\n",
      "{output}\n",
      "\n",
      "{grading_context_columns}\n",
      "\n",
      "Metric definition:\n",
      "This metric evaluates how well a user‚Äôs vague or informal movie request is reformulated into a clear, detailed, and embedding-friendly description. An ideal reformulation avoids specific movie titles, character names, or fictional details, and instead emphasizes genre, tone, themes, pacing, emotional goals, and the type of ending the user is looking for.\n",
      "\n",
      "Grading rubric:\n",
      "Embedding-friendly rewriting: The goal is to transform a vague user request into a richly detailed, general description of the desired movie, without referencing specific titles or inventing fake storylines. Use the following scale: - Score 1: Response is vague, off-topic, or mostly repeats the original input without useful elaboration. - Score 2: Response adds some detail but includes specific movies, names, or plot points. - Score 3: Response is mostly general and meaningful but lacks depth or has slight specific references. - Score 4: Response is clear, general, and detailed, capturing the user‚Äôs intent well without referencing specific titles. - Score 5: Response is richly detailed, entirely general, and fully expresses the user's intent with precision. Ideal for semantic search embeddings.\n",
      "\n",
      "Examples:\n",
      "\n",
      "Example Input:\n",
      "Something emotional, like The Pursuit of Happyness, but without too much sadness.\n",
      "\n",
      "Example Output:\n",
      "I‚Äôm looking for an emotional drama that captures the resilience of the human spirit, focusing on themes of hope and perseverance in the face of adversity. I want it to tell a heartfelt story about an individual's journey, showcasing their struggles but emphasizing uplifting moments and personal triumphs that bring warmth and inspiration. The pacing should be steady, allowing me to connect deeply with the characters and their experiences, while maintaining an atmosphere that feels both relatable and encouraging. I expect an ending that leaves me with a sense of fulfillment and optimism, where the protagonist not only overcomes their challenges but also experiences growth and newfound joy in their life.\n",
      "\n",
      "Example score: 5\n",
      "Example justification: The response is highly detailed, avoids specific movie names or characters, and effectively captures the user's emotional and thematic intent. It reads like a structured expression of what the user wants and is ideal for embedding-based matching.\n",
      "        \n",
      "\n",
      "You must return the following fields in your response in two lines, one below the other:\n",
      "score: Your numerical score for the model's embedding_friendly_rewriting based on the rubric\n",
      "justification: Your reasoning about the model's embedding_friendly_rewriting score\n",
      "\n",
      "Do not add additional new lines. Do not add any other fields.\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "from mlflow.metrics.genai import EvaluationExample, make_genai_metric\n",
    "\n",
    "embedding_friendly_metric = make_genai_metric(\n",
    "    name=\"embedding_friendly_rewriting\",\n",
    "    definition=(\n",
    "        \"This metric evaluates how well a user‚Äôs vague or informal movie request is reformulated into a clear, detailed, and embedding-friendly description. \"\n",
    "        \"An ideal reformulation avoids specific movie titles, character names, or fictional details, and instead emphasizes genre, tone, themes, pacing, emotional goals, and the type of ending the user is looking for.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Embedding-friendly rewriting: The goal is to transform a vague user request into a richly detailed, general description of the desired movie, \"\n",
    "        \"without referencing specific titles or inventing fake storylines. Use the following scale: \"\n",
    "        \"- Score 1: Response is vague, off-topic, or mostly repeats the original input without useful elaboration. \"\n",
    "        \"- Score 2: Response adds some detail but includes specific movies, names, or plot points. \"\n",
    "        \"- Score 3: Response is mostly general and meaningful but lacks depth or has slight specific references. \"\n",
    "        \"- Score 4: Response is clear, general, and detailed, capturing the user‚Äôs intent well without referencing specific titles. \"\n",
    "        \"- Score 5: Response is richly detailed, entirely general, and fully expresses the user's intent with precision. Ideal for semantic search embeddings.\"\n",
    "    ),\n",
    "    examples=[\n",
    "        EvaluationExample(\n",
    "            input=\"Something emotional, like The Pursuit of Happyness, but without too much sadness.\",\n",
    "            output=(\n",
    "                \"I‚Äôm looking for an emotional drama that captures the resilience of the human spirit, focusing on themes of hope and perseverance in the face of adversity. \"\n",
    "                \"I want it to tell a heartfelt story about an individual's journey, showcasing their struggles but emphasizing uplifting moments and personal triumphs that bring warmth and inspiration. \"\n",
    "                \"The pacing should be steady, allowing me to connect deeply with the characters and their experiences, while maintaining an atmosphere that feels both relatable and encouraging. \"\n",
    "                \"I expect an ending that leaves me with a sense of fulfillment and optimism, where the protagonist not only overcomes their challenges but also experiences growth and newfound joy in their life.\"\n",
    "            ),\n",
    "            score=5,\n",
    "            justification=(\n",
    "                \"The response is highly detailed, avoids specific movie names or characters, and effectively captures the user's emotional and thematic intent. \"\n",
    "                \"It reads like a structured expression of what the user wants and is ideal for embedding-based matching.\"\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    version=\"v1\",\n",
    "    model=\"openai:/gpt-4\",\n",
    "    parameters={\"temperature\": 0.0},\n",
    "    grading_context_columns=[],\n",
    "    aggregations=[\"mean\", \"variance\", \"p90\"],\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "print(embedding_friendly_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d80e4fcb-aae1-4e81-9180-1daf5f0db33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 98.47it/s]\n",
      "2025/06/19 14:31:43 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-0f015ef569384a8d94d3947551dea793\n",
      "2025/06/19 14:31:43 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:31:43 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2025/06/19 14:31:47 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2025/06/19 14:31:47 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:31:47 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:47 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:31:47 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:47 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:31:47 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:47 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.77s/it]\n",
      "2025/06/19 14:31:51 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:31:51 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:51 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:31:51 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:51 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:31:51 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:31:51 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run gentle-squid-204 at: http://0.0.0.0:5001/#/experiments/973507716245173164/runs/d93fdbec448848afb54bb7967b6ee208\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/973507716245173164\n",
      "{'embedding_friendly_rewriting/v1/mean': np.float64(4.8), 'embedding_friendly_rewriting/v1/variance': np.float64(0.15999999999999998), 'embedding_friendly_rewriting/v1/p90': np.float64(5.0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=8c2e3707b4204c10aa5f94460a1ffd3b&amp;experiment_id=973507716245173164&amp;trace_id=84c2533dfea341a18f12d4fea0fe34f4&amp;experiment_id=973507716245173164&amp;trace_id=d47d6cfda59442149b9abd0f393fc377&amp;experiment_id=973507716245173164&amp;trace_id=06930f365648418d903ad1f9ed5e1f3c&amp;experiment_id=973507716245173164&amp;trace_id=2d14f3396d3945f2b88224840fbab0af&amp;experiment_id=973507716245173164&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=8c2e3707b4204c10aa5f94460a1ffd3b), Trace(trace_id=84c2533dfea341a18f12d4fea0fe34f4), Trace(trace_id=d47d6cfda59442149b9abd0f393fc377), Trace(trace_id=06930f365648418d903ad1f9ed5e1f3c), Trace(trace_id=2d14f3396d3945f2b88224840fbab0af)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    results = mlflow.evaluate(\n",
    "        basic_qa_model.model_uri,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[embedding_friendly_metric],  # use the professionalism metric we created above\n",
    "    )\n",
    "print(results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bec8367-bb0c-43f4-8a23-8370879c9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 169.34it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 33.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>outputs</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding_friendly_rewriting/v1/score</th>\n",
       "      <th>embedding_friendly_rewriting/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want a movie like The Matrix, but with a dee...</td>\n",
       "      <td>A science fiction movie set in a dystopian fut...</td>\n",
       "      <td>I‚Äôm looking for a science fiction movie that d...</td>\n",
       "      <td>161</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Something emotional, like The Pursuit of Happy...</td>\n",
       "      <td>An inspiring drama following a determined prot...</td>\n",
       "      <td>I'm looking for an emotional drama that emphas...</td>\n",
       "      <td>161</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is clear, general, and detailed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A crime movie like Breaking Bad, but focused o...</td>\n",
       "      <td>A gritty crime drama centered around a morally...</td>\n",
       "      <td>I'm looking for a gripping crime drama that de...</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want a romantic movie that‚Äôs not cheesy and ...</td>\n",
       "      <td>A grounded romantic drama portraying the evolv...</td>\n",
       "      <td>I‚Äôm looking for a romantic film that strikes a...</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A slow-paced sci-fi movie like Arrival, with a...</td>\n",
       "      <td>A contemplative science fiction film where the...</td>\n",
       "      <td>I‚Äôm looking for a slow-paced sci-fi movie that...</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  I want a movie like The Matrix, but with a dee...   \n",
       "1  Something emotional, like The Pursuit of Happy...   \n",
       "2  A crime movie like Breaking Bad, but focused o...   \n",
       "3  I want a romantic movie that‚Äôs not cheesy and ...   \n",
       "4  A slow-paced sci-fi movie like Arrival, with a...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  A science fiction movie set in a dystopian fut...   \n",
       "1  An inspiring drama following a determined prot...   \n",
       "2  A gritty crime drama centered around a morally...   \n",
       "3  A grounded romantic drama portraying the evolv...   \n",
       "4  A contemplative science fiction film where the...   \n",
       "\n",
       "                                             outputs  token_count  \\\n",
       "0  I‚Äôm looking for a science fiction movie that d...          161   \n",
       "1  I'm looking for an emotional drama that emphas...          161   \n",
       "2  I'm looking for a gripping crime drama that de...          171   \n",
       "3  I‚Äôm looking for a romantic film that strikes a...          159   \n",
       "4  I‚Äôm looking for a slow-paced sci-fi movie that...          154   \n",
       "\n",
       "   embedding_friendly_rewriting/v1/score  \\\n",
       "0                                      5   \n",
       "1                                      4   \n",
       "2                                      5   \n",
       "3                                      5   \n",
       "4                                      5   \n",
       "\n",
       "       embedding_friendly_rewriting/v1/justification  \n",
       "0  The model's response is highly detailed, avoid...  \n",
       "1  The response is clear, general, and detailed, ...  \n",
       "2  The model's response is highly detailed, avoid...  \n",
       "3  The model's response is highly detailed, avoid...  \n",
       "4  The model's response is highly detailed, avoid...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables[\"eval_results_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41bbcace-c595-48fd-85e7-5cba720191d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 261.40it/s]\n",
      "2025/06/19 14:35:01 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-a5640aaae9c64d4189342aab64aedde1\n",
      "2025/06/19 14:35:01 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:35:02 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-a5640aaae9c64d4189342aab64aedde1\n",
      "2025/06/19 14:35:02 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/06/19 14:35:02 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2025/06/19 14:35:07 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2025/06/19 14:35:07 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:35:07 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:07 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:35:07 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:07 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:35:07 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:07 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.46s/it]\n",
      "2025/06/19 14:35:11 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2025/06/19 14:35:11 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:11 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:35:11 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:11 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
      "2025/06/19 14:35:11 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'ari_grade_level' at index 3 in the `extra_metrics` parameter because it returned None.\n",
      "2025/06/19 14:35:11 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run languid-panda-912 at: http://0.0.0.0:5001/#/experiments/973507716245173164/runs/e837d81a55234cea9a67a61c7d11d3bd\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/973507716245173164\n",
      "{'embedding_friendly_rewriting/v1/mean': np.float64(5.0), 'embedding_friendly_rewriting/v1/variance': np.float64(0.0), 'embedding_friendly_rewriting/v1/p90': np.float64(5.0)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=a3b95f66ee1046df84130f8558401223&amp;experiment_id=973507716245173164&amp;trace_id=047d4973b3d94cec9166f695287f9c62&amp;experiment_id=973507716245173164&amp;trace_id=da14e57e5586497faa63a4adc42d696b&amp;experiment_id=973507716245173164&amp;trace_id=62fa26b75a5a422790873231c677b09b&amp;experiment_id=973507716245173164&amp;trace_id=8dd88eda571047bc9ecb4d7f4ef1b09e&amp;experiment_id=973507716245173164&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=a3b95f66ee1046df84130f8558401223), Trace(trace_id=047d4973b3d94cec9166f695287f9c62), Trace(trace_id=da14e57e5586497faa63a4adc42d696b), Trace(trace_id=62fa26b75a5a422790873231c677b09b), Trace(trace_id=8dd88eda571047bc9ecb4d7f4ef1b09e)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    system_prompt = SYSTEM_PROMPT\n",
    "    professional_qa_model = mlflow.openai.log_model(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        task=openai.chat.completions,\n",
    "        name=\"model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "        ],\n",
    "    )\n",
    "    results = mlflow.evaluate(\n",
    "        professional_qa_model.model_uri,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[embedding_friendly_metric],\n",
    "    )\n",
    "print(results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72d31363-5f16-4c13-a333-877cd51a017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.24it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 209.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>outputs</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding_friendly_rewriting/v1/score</th>\n",
       "      <th>embedding_friendly_rewriting/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want a movie like The Matrix, but with a dee...</td>\n",
       "      <td>A science fiction movie set in a dystopian fut...</td>\n",
       "      <td>I‚Äôm looking for a thought-provoking science fi...</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Something emotional, like The Pursuit of Happy...</td>\n",
       "      <td>An inspiring drama following a determined prot...</td>\n",
       "      <td>I‚Äôm looking for a heartfelt drama that strikes...</td>\n",
       "      <td>177</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A crime movie like Breaking Bad, but focused o...</td>\n",
       "      <td>A gritty crime drama centered around a morally...</td>\n",
       "      <td>I‚Äôm looking for a gripping crime drama that de...</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want a romantic movie that‚Äôs not cheesy and ...</td>\n",
       "      <td>A grounded romantic drama portraying the evolv...</td>\n",
       "      <td>I‚Äôm looking for a romantic movie that strikes ...</td>\n",
       "      <td>147</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A slow-paced sci-fi movie like Arrival, with a...</td>\n",
       "      <td>A contemplative science fiction film where the...</td>\n",
       "      <td>I‚Äôm looking for a slow-paced sci-fi film that ...</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>The model's response is highly detailed, avoid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  I want a movie like The Matrix, but with a dee...   \n",
       "1  Something emotional, like The Pursuit of Happy...   \n",
       "2  A crime movie like Breaking Bad, but focused o...   \n",
       "3  I want a romantic movie that‚Äôs not cheesy and ...   \n",
       "4  A slow-paced sci-fi movie like Arrival, with a...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  A science fiction movie set in a dystopian fut...   \n",
       "1  An inspiring drama following a determined prot...   \n",
       "2  A gritty crime drama centered around a morally...   \n",
       "3  A grounded romantic drama portraying the evolv...   \n",
       "4  A contemplative science fiction film where the...   \n",
       "\n",
       "                                             outputs  token_count  \\\n",
       "0  I‚Äôm looking for a thought-provoking science fi...          184   \n",
       "1  I‚Äôm looking for a heartfelt drama that strikes...          177   \n",
       "2  I‚Äôm looking for a gripping crime drama that de...          180   \n",
       "3  I‚Äôm looking for a romantic movie that strikes ...          147   \n",
       "4  I‚Äôm looking for a slow-paced sci-fi film that ...          138   \n",
       "\n",
       "   embedding_friendly_rewriting/v1/score  \\\n",
       "0                                      5   \n",
       "1                                      5   \n",
       "2                                      5   \n",
       "3                                      5   \n",
       "4                                      5   \n",
       "\n",
       "       embedding_friendly_rewriting/v1/justification  \n",
       "0  The model's response is highly detailed, avoid...  \n",
       "1  The model's response is highly detailed, avoid...  \n",
       "2  The model's response is highly detailed, avoid...  \n",
       "3  The model's response is highly detailed, avoid...  \n",
       "4  The model's response is highly detailed, avoid...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables[\"eval_results_table\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
