{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QgumzOZ5wgec",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Training with K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rByuPhg7wgei",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zw5Tap_Xwgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VqGH1Mr6wgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "More information about the dataset can be found in UCI machine learning repository: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
    "\n",
    "Acknowledgement: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36Gk-YMhwgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download original dataset with: python src/load_data.py \n",
    "\n",
    "raw_data = pd.read_csv(f\"../data/raw_data.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dhZOCJZ1wgel",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define column mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i8edS6Ewgem",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "datetime = 'dteday'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'mnth', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday', ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q5lW24Xzwgex",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the comparison windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6PKtAGEwgey",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_date_0 = '2011-01-02 00:00:00'\n",
    "end_date_0 = '2011-01-30 23:00:00'\n",
    "\n",
    "experiment_batches = [\n",
    "    \n",
    "    ('2011-01-31 00:00:00','2011-02-06 23:00:00'),\n",
    "    ('2011-02-07 23:00:00','2011-02-13 23:00:00'),\n",
    "    ('2011-02-14 23:00:00','2011-02-20 23:00:00'),\n",
    "    ('2011-02-21 00:00:00','2011-02-27 23:00:00'),\n",
    "    ('2011-02-28 00:00:00','2011-03-06 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datetime index \n",
    "raw_data = raw_data.set_index('dteday')\n",
    "\n",
    "# Define the reference dataset\n",
    "reference = raw_data.loc[start_date_0:end_date_0]\n",
    "\n",
    "print(reference.shape)\n",
    "reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLFlow Client\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new Experiment\n",
    "\n",
    "In order to group any distinct runs of a particular project or idea together, we can define an Experiment that will group each iteration (runs) together. \n",
    "Defining a unique name that is relevant to what we're working on helps with organization and reduces the amount of work (searching) to find our runs later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an experiment by name if it exists\n",
    "\n",
    "experiment_id = client.get_experiment_by_name('1-Train-K-Fold')\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new experiment if it doesn't exist\n",
    "\n",
    "if not experiment_id:\n",
    "    experiment_id = client.create_experiment('1-Train-K-Fold')\n",
    "    \n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch experiment metadata information\n",
    "\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(f\"Name: {experiment.name}\")\n",
    "print(f\"Experiment_id: {experiment.experiment_id}\")\n",
    "print(f\"Artifact Location: {experiment.artifact_location}\")\n",
    "print(f\"Tags: {experiment.tags}\")\n",
    "print(f\"Lifecycle_stage: {experiment.lifecycle_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Tracking for K-Fold Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTHU8eAqwgez",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "mlflow.set_experiment('1-Train-K-Fold') # Create a new Experiment if it doesn't exist\n",
    "\n",
    "# Set experiment variables\n",
    "model_path = Path('../models/model.joblib')\n",
    "ref_end_data = end_date_0\n",
    "\n",
    "# Run model train for each batch (K-Fold)\n",
    "for k, date in enumerate(experiment_batches):\n",
    "\n",
    "    print(f\"Train period: {start_date_0} - {ref_end_data}\") \n",
    "    X_train = raw_data.loc[start_date_0:ref_end_data, numerical_features + categorical_features]\n",
    "    y_train = raw_data.loc[start_date_0:ref_end_data, target]\n",
    "    print(\"X_train (reference) dataset shape: \", X_train.shape, y_train.shape)\n",
    "    \n",
    "    print(f\"Test period: {date[0]} - {date[1]}\") \n",
    "    current = raw_data.loc[date[0]:date[1]]\n",
    "    X_test = current.loc[:, numerical_features + categorical_features]\n",
    "    y_test = current[target]\n",
    "    print(\"X_test (current)) dataset shape: \",  X_test.shape, y_test.shape)\n",
    "\n",
    "    # Train model\n",
    "    regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate metrics\n",
    "    preds = regressor.predict(X_test)\n",
    "    me = mean_squared_error(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    # print(me, mae)\n",
    "    \n",
    "    # Start a new MLflow Run\n",
    "    with mlflow.start_run() as run: \n",
    "        \n",
    "        # Show newly created run metadata info\n",
    "        print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "        print(\"Run id: {}\".format(run.info.run_id))\n",
    "        print(\"Run name: {}\".format(run.info.run_name))\n",
    "        print('MLFlow tracking uri:', mlflow.get_tracking_uri())\n",
    "        print('MLFlow artifact uri:', mlflow.get_artifact_uri())\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"begin\", date[0])\n",
    "        mlflow.log_param(\"end\", date[1])\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric('me', round(me, 3))\n",
    "        mlflow.log_metric('mae', round(mae, 3))\n",
    "        \n",
    "        # Log model \n",
    "        mlflow.log_artifact(model_path)\n",
    "\n",
    "    # Update reference end date\n",
    "    ref_end_data = date[1]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLFlow Client\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set experiment name\n",
    "mlflow.set_experiment('2-Nested-Runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set experiment variables\n",
    "model_path = Path('../models/model.joblib')\n",
    "ref_end_data = end_date_0\n",
    "\n",
    "# Start a new Run (Parent Run)\n",
    "with mlflow.start_run() as run: \n",
    "    \n",
    "    # Update metrics with metrics for each Fold\n",
    "    metrics = {}\n",
    "\n",
    "    # Run model train for each batch (K-Fold)\n",
    "    for k, date in enumerate(experiment_batches):\n",
    "            \n",
    "        print(f\"Train period: {start_date_0} - {ref_end_data}\") \n",
    "        X_train = raw_data.loc[start_date_0:ref_end_data, numerical_features + categorical_features]\n",
    "        y_train = raw_data.loc[start_date_0:ref_end_data, target]\n",
    "        print(\"X_train (reference) dataset shape: \", X_train.shape, y_train.shape)\n",
    "        \n",
    "        print(f\"Test period: {date[0]} - {date[1]}\") \n",
    "        current = raw_data.loc[date[0]:date[1]]\n",
    "        X_test = current.loc[:, numerical_features + categorical_features]\n",
    "        y_test = current[target]\n",
    "        print(\"X_test (current)) dataset shape: \",  X_test.shape, y_test.shape)\n",
    "        \n",
    "        # Update reference end date\n",
    "        ref_end_data = date[1]\n",
    "\n",
    "        # Train model\n",
    "        regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "        regressor.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate metrucs\n",
    "        preds = regressor.predict(X_test)\n",
    "        me = mean_squared_error(y_test, preds)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        metrics.update({date[1]: {'me': me, 'mae': mae}})\n",
    "        \n",
    "        # Run a Child Run for each Fold \n",
    "        with mlflow.start_run(run_name=date[1], nested=True) as child_run:\n",
    "            \n",
    "            # Show newly created run metadata info\n",
    "            print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "            print(\"Run id: {}\".format(run.info.run_id))\n",
    "            print(\"Run name: {}\".format(run.info.run_name))\n",
    "            print('MLFlow tracking uri:', mlflow.get_tracking_uri())\n",
    "            print('MLFlow artifact uri:', mlflow.get_artifact_uri())\n",
    "            \n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"begin\", date[0])\n",
    "            mlflow.log_param(\"end\", date[1])\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric('me', round(me, 3))\n",
    "            mlflow.log_metric('mae', round(mae, 3))\n",
    "        \n",
    "    # Save model\n",
    "    joblib.dump(regressor, model_path)\n",
    "\n",
    "    # Log the last batch model as the parent Run model\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    # Log metrics\n",
    "    average_run_merics = pd.DataFrame.from_dict(metrics).T.mean().round(3).to_dict()\n",
    "    mlflow.log_metrics(average_run_merics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log metrics by steps or timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Set up MLFlow Client\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "# Set experiment name\n",
    "mlflow.set_experiment('3-Metrics-by-steps')\n",
    "\n",
    "# Set experiment variables\n",
    "model_path = Path('../models/model.joblib')\n",
    "ref_end_data = end_date_0\n",
    "\n",
    "# Start a new MLflow Run\n",
    "with mlflow.start_run() as run: \n",
    "\n",
    "    # Run model train for each batch (K-Fold)\n",
    "    for k, date in enumerate(experiment_batches):\n",
    "\n",
    "        # Calculate timestamp\n",
    "        timestamp = time.mktime(datetime.datetime.strptime(date[1], \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "    \n",
    "        print(f\"Train period: {start_date_0} - {ref_end_data}\") \n",
    "        X_train = raw_data.loc[start_date_0:ref_end_data, numerical_features + categorical_features]\n",
    "        y_train = raw_data.loc[start_date_0:ref_end_data, target]\n",
    "        print(\"X_train (reference) dataset shape: \", X_train.shape, y_train.shape)\n",
    "        \n",
    "        print(f\"Test period: {date[0]} - {date[1]}\") \n",
    "        current = raw_data.loc[date[0]:date[1]]\n",
    "        X_test = current.loc[:, numerical_features + categorical_features]\n",
    "        y_test = current[target]\n",
    "        print(\"X_test (current)) dataset shape: \",  X_test.shape, y_test.shape)\n",
    "        \n",
    "        # Update reference end date\n",
    "        ref_end_data = date[1]\n",
    "        \n",
    "        # Train model\n",
    "        regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "        regressor.fit(X_train, y_train)\n",
    "    \n",
    "        # Calculate metrics\n",
    "        preds = regressor.predict(X_test)\n",
    "        me = mean_squared_error(y_test, preds)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        # print(me, mae)\n",
    "        \n",
    "        # Log metrics (use Client)\n",
    "        # >>> 'timestamp' - Time when this metric was calculated. Defaults to the current system time\n",
    "        # >>> 'step' -  Integer training step (iteration) at which was the metric calculated. Defaults to 0.\n",
    "        client.log_metric(run.info.run_id, 'me', round(me, 3), timestamp=int(timestamp)*1000)\n",
    "        client.log_metric(run.info.run_id, 'mae', round(mae, 3), step=k)\n",
    "\n",
    "    # Log model \n",
    "    mlflow.log_artifact(model_path)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"begin\", date[0])\n",
    "    mlflow.log_param(\"end\", date[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
